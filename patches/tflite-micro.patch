diff --git tensorflow/lite/micro/memory_planner/greedy_memory_planner.h tensorflow/lite/micro/memory_planner/greedy_memory_planner.h
index a34f3c5..79839ef 100644
--- tensorflow/lite/micro/memory_planner/greedy_memory_planner.h
+++ tensorflow/lite/micro/memory_planner/greedy_memory_planner.h
@@ -109,6 +109,8 @@ class GreedyMemoryPlanner : public MicroMemoryPlanner {
     return per_buffer_size;
   }
 
+  TF_LITE_REMOVE_VIRTUAL_DELETE
+
  private:
   // Whether a buffer is active in a given time range.
   bool DoesEntryOverlapInTime(const ListEntry* entry, const int first_time_used,
@@ -158,8 +160,6 @@ class GreedyMemoryPlanner : public MicroMemoryPlanner {
 
   // Whether buffers have been added since the last plan was calculated.
   bool need_to_calculate_offsets_;
-
-  TF_LITE_REMOVE_VIRTUAL_DELETE
 };
 
 }  // namespace tflite
diff --git tensorflow/lite/micro/micro_allocator.h tensorflow/lite/micro/micro_allocator.h
index f9660cf..7c8dd03 100644
--- tensorflow/lite/micro/micro_allocator.h
+++ tensorflow/lite/micro/micro_allocator.h
@@ -233,6 +233,12 @@ class MicroAllocator {
 
   BuiltinDataAllocator* GetBuiltinDataAllocator();
 
+  MicroMemoryPlanner* memory_planner() { return memory_planner_;}
+
+  // Returns the pointer for the array of ScratchBufferRequest allocations in
+  // the head section.
+  internal::ScratchBufferRequest* GetScratchBufferRequests();
+
  protected:
   MicroAllocator(SingleArenaBufferAllocator* memory_allocator,
                  MicroMemoryPlanner* memory_planner,
@@ -296,10 +302,6 @@ class MicroAllocator {
   // preparing.
   TfLiteStatus InitScratchBufferData();
 
-  // Returns the pointer for the array of ScratchBufferRequest allocations in
-  // the head section.
-  internal::ScratchBufferRequest* GetScratchBufferRequests();
-
   // A simple memory allocator that always allocate from the arena tail or head.
   INonPersistentBufferAllocator* non_persistent_buffer_allocator_;
   IPersistentBufferAllocator* persistent_buffer_allocator_;
diff --git tensorflow/lite/micro/micro_context.h tensorflow/lite/micro/micro_context.h
index e7be654..1428a18 100644
--- tensorflow/lite/micro/micro_context.h
+++ tensorflow/lite/micro/micro_context.h
@@ -20,6 +20,22 @@ limitations under the License.
 #include "tensorflow/lite/micro/micro_allocator.h"
 #include "tensorflow/lite/micro/micro_graph.h"
 
+#ifdef NO_INTERPRETER
+
+namespace tflite {
+  struct MicroContext{
+      TfLiteTensor* (*AllocateTempInputTensor)(const TfLiteNode* node, int index);
+      TfLiteTensor* (*AllocateTempOutputTensor)(const TfLiteNode* node, int index);
+      void (*DeallocateTempTfLiteTensor)(TfLiteTensor* tensor);
+      void* (*external_context)();
+  };
+  static MicroContext* GetMicroContext(const struct TfLiteContext* context){
+      return reinterpret_cast<MicroContext*>(context->impl_);
+  }
+}
+
+#else
+
 namespace tflite {
 // MicroContext is eventually going to become the API between TFLM and the
 // kernels, replacing all the functions in TfLiteContext. The end state is code
@@ -158,4 +174,6 @@ void MicroContextReportOpError(struct TfLiteContext* context,
 
 }  // namespace tflite
 
+#endif  // NO_INTERPRETER
+
 #endif  // TENSORFLOW_LITE_MICRO_MICRO_CONTEXT_H_
diff --git tensorflow/lite/micro/micro_error_reporter.h tensorflow/lite/micro/micro_error_reporter.h
index 0e3b0c3..27388e0 100644
--- tensorflow/lite/micro/micro_error_reporter.h
+++ tensorflow/lite/micro/micro_error_reporter.h
@@ -46,8 +46,6 @@ class MicroErrorReporter : public ErrorReporter {
  public:
   ~MicroErrorReporter() override {}
   int Report(const char* format, va_list args) override;
-
- private:
   TF_LITE_REMOVE_VIRTUAL_DELETE
 };
 
diff --git tensorflow/lite/micro/micro_interpreter.h tensorflow/lite/micro/micro_interpreter.h
index ae7fc8f..5c2fd6e 100644
--- tensorflow/lite/micro/micro_interpreter.h
+++ tensorflow/lite/micro/micro_interpreter.h
@@ -140,6 +140,13 @@ class MicroInterpreter {
   // arena_used_bytes() + 16.
   size_t arena_used_bytes() const { return allocator_.used_bytes(); }
 
+  size_t operators_size() const { return model_->subgraphs()->Get(0)->operators()->size(); }
+
+  // For debugging only.
+  const NodeAndRegistration node_and_registration(int node_index)  {
+    return graph_.GetAllocations()[0].node_and_registrations[node_index];
+  }
+
  protected:
   const MicroAllocator& allocator() const { return allocator_; }
   const TfLiteContext& context() const { return context_; }
diff --git tensorflow/lite/micro/test_helpers.cc tensorflow/lite/micro/test_helpers.cc
index 2411bbf..875f10b 100644
--- tensorflow/lite/micro/test_helpers.cc
+++ tensorflow/lite/micro/test_helpers.cc
@@ -444,11 +444,19 @@ const Model* BuildModelWithUnusedOperatorOutputs() {
           *builder, builder->CreateVector(tensor_shape, tensor_shape_size),
           TensorType_INT8, 0,
           builder->CreateString("test_unused_output_tensor"), 0, false)};
+#ifdef _MSC_VER
+  constexpr size_t inputs_size = 1;
+#else
   constexpr size_t inputs_size = 0;
+#endif
   const int32_t inputs[inputs_size] = {};
   constexpr size_t outputs_size = 1;
   const int32_t outputs[outputs_size] = {0};
+#ifdef _MSC_VER
+  constexpr size_t operator_inputs_size = 1;
+#else
   constexpr size_t operator_inputs_size = 0;
+#endif
   const int32_t operator_inputs[operator_inputs_size] = {};
   constexpr size_t operator_outputs_size = 2;
   const int32_t operator_outputs[operator_outputs_size] = {0, 1};
